{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e706d-ba20-4261-a706-9bbb310f8a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:44:36.916634Z",
     "iopub.status.busy": "2025-07-23T07:44:36.916299Z",
     "iopub.status.idle": "2025-07-23T07:47:54.857724Z",
     "shell.execute_reply": "2025-07-23T07:47:54.856961Z",
     "shell.execute_reply.started": "2025-07-23T07:44:36.916611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install transformers==4.41.2\n",
    "%pip install torch --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install huggingface_hub\n",
    "%pip install datasets==3.6.0\n",
    "%pip install accelerate==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc712a74-2775-4189-a0a1-feecf81bb037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install datasets==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496b8e2-f486-45b1-9860-119b5e282466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:50:18.256835Z",
     "iopub.status.busy": "2025-07-23T07:50:18.256456Z",
     "iopub.status.idle": "2025-07-23T07:50:43.622945Z",
     "shell.execute_reply": "2025-07-23T07:50:43.621735Z",
     "shell.execute_reply.started": "2025-07-23T07:50:18.256809Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750f1e7-4ef8-4e58-bfdb-08b8c55b6a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:50:47.692846Z",
     "iopub.status.busy": "2025-07-23T07:50:47.692481Z",
     "iopub.status.idle": "2025-07-23T07:50:47.796373Z",
     "shell.execute_reply": "2025-07-23T07:50:47.795574Z",
     "shell.execute_reply.started": "2025-07-23T07:50:47.692824Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ANS_RE = re.compile(r'####\\s(.*)$', re.DOTALL)\n",
    "REMOVE_ANNOTATION = re.compile(r'<<.*?>>')\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B\"\n",
    "OUTPUT_DIR = '/home/jupyter/datasphere/project/check_sft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52660c6b-0de8-446e-b6bf-cdba5093c42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:50:50.135258Z",
     "iopub.status.busy": "2025-07-23T07:50:50.134906Z",
     "iopub.status.idle": "2025-07-23T07:50:50.204689Z",
     "shell.execute_reply": "2025-07-23T07:50:50.203666Z",
     "shell.execute_reply.started": "2025-07-23T07:50:50.135238Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288db8ab-ae89-494f-8ed9-c2212b20eba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:50:51.879049Z",
     "iopub.status.busy": "2025-07-23T07:50:51.878623Z",
     "iopub.status.idle": "2025-07-23T07:54:21.246972Z",
     "shell.execute_reply": "2025-07-23T07:54:21.245631Z",
     "shell.execute_reply.started": "2025-07-23T07:50:51.879030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959db65-5ed8-4e3a-977e-2efd57ad9598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:54:28.718844Z",
     "iopub.status.busy": "2025-07-23T07:54:28.718446Z",
     "iopub.status.idle": "2025-07-23T07:54:41.325640Z",
     "shell.execute_reply": "2025-07-23T07:54:41.324821Z",
     "shell.execute_reply.started": "2025-07-23T07:54:28.718820Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217002b0-6d16-4ae7-848c-09f3908a290f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:54:46.259865Z",
     "iopub.status.busy": "2025-07-23T07:54:46.259453Z",
     "iopub.status.idle": "2025-07-23T07:54:46.288616Z",
     "shell.execute_reply": "2025-07-23T07:54:46.287812Z",
     "shell.execute_reply.started": "2025-07-23T07:54:46.259844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hendrycks_math(split=\"train\") -> Dataset:\n",
    "    ds = load_dataset(\"nlile/hendrycks-MATH-benchmark\", split=split)\n",
    "    def preprocess(x):\n",
    "        # Составляем единый текстовый prompt\n",
    "        prompt = SYSTEM_PROMPT + \" Problem: \" + x[\"problem\"]\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"solution\": x[\"solution\"],\n",
    "            \"answer\": x[\"answer\"],\n",
    "        }\n",
    "    return ds.map(preprocess, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cddcd-6d89-4f18-b79b-e23851d857fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:54:48.446518Z",
     "iopub.status.busy": "2025-07-23T07:54:48.446152Z",
     "iopub.status.idle": "2025-07-23T07:54:50.854319Z",
     "shell.execute_reply": "2025-07-23T07:54:50.853467Z",
     "shell.execute_reply.started": "2025-07-23T07:54:48.446498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = get_hendrycks_math()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120e474-8025-4313-ad9f-9acb5ce8fcc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:54:55.509559Z",
     "iopub.status.busy": "2025-07-23T07:54:55.509083Z",
     "iopub.status.idle": "2025-07-23T07:54:55.566029Z",
     "shell.execute_reply": "2025-07-23T07:54:55.564963Z",
     "shell.execute_reply.started": "2025-07-23T07:54:55.509536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae30873-f644-434f-9ac2-95da2086878c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:54:57.240430Z",
     "iopub.status.busy": "2025-07-23T07:54:57.239927Z",
     "iopub.status.idle": "2025-07-23T07:54:57.262114Z",
     "shell.execute_reply": "2025-07-23T07:54:57.261300Z",
     "shell.execute_reply.started": "2025-07-23T07:54:57.240408Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    processed_inputs = []\n",
    "    prompts   = examples[\"prompt\"]\n",
    "    solutions = examples[\"solution\"]\n",
    "    \n",
    "    for prompt, solution in zip(prompts, solutions):\n",
    "        # просто полный текст = prompt + решение\n",
    "        full_text = prompt + solution\n",
    "\n",
    "        # токенизируем без паддинга\n",
    "        full_toks = tokenizer(\n",
    "            full_text,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "        prompt_toks = tokenizer(\n",
    "            prompt,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        input_ids      = full_toks[\"input_ids\"]\n",
    "        attention_mask = full_toks[\"attention_mask\"]\n",
    "        labels         = input_ids.copy()\n",
    "\n",
    "        # маскируем всё, что относится к prompt\n",
    "        prompt_len = len(prompt_toks[\"input_ids\"])\n",
    "        if prompt_len < len(labels):\n",
    "            labels[:prompt_len] = [-100] * prompt_len\n",
    "        else:\n",
    "            labels = [-100] * len(labels)\n",
    "\n",
    "        processed_inputs.append({\n",
    "            \"input_ids\":      input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\":         labels,\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"input_ids\":      [x[\"input_ids\"]      for x in processed_inputs],\n",
    "        \"attention_mask\":[x[\"attention_mask\"] for x in processed_inputs],\n",
    "        \"labels\":         [x[\"labels\"]         for x in processed_inputs],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec929ed4-e2cf-4881-9af3-1273549da0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:54:58.795635Z",
     "iopub.status.busy": "2025-07-23T07:54:58.795201Z",
     "iopub.status.idle": "2025-07-23T07:54:59.403769Z",
     "shell.execute_reply": "2025-07-23T07:54:59.402908Z",
     "shell.execute_reply.started": "2025-07-23T07:54:58.795614Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names  # удаляем старые поля\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9211902-d8b9-4ebd-8cfc-0c63ad656281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:55:01.923787Z",
     "iopub.status.busy": "2025-07-23T07:55:01.923277Z",
     "iopub.status.idle": "2025-07-23T07:55:01.979984Z",
     "shell.execute_reply": "2025-07-23T07:55:01.979154Z",
     "shell.execute_reply.started": "2025-07-23T07:55:01.923761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, features):\n",
    "        input_ids = [f[\"input_ids\"] for f in features]\n",
    "        attention_mask = [f[\"attention_mask\"] for f in features]\n",
    "        labels = [f[\"labels\"] for f in features]\n",
    "\n",
    "        max_len = min(max(len(ids) for ids in input_ids), self.max_length)\n",
    "\n",
    "        padded_input_ids = []\n",
    "        padded_attention_mask = []\n",
    "        padded_labels = []\n",
    "\n",
    "        for ids, mask, label in zip(input_ids, attention_mask, labels):\n",
    "            ids = ids[:max_len]\n",
    "            mask = mask[:max_len]\n",
    "            label = label[:max_len]\n",
    "\n",
    "            pad_length = max_len - len(ids)\n",
    "            if pad_length > 0:\n",
    "                ids += [self.tokenizer.pad_token_id] * pad_length\n",
    "                mask += [0] * pad_length\n",
    "                label += [-100] * pad_length\n",
    "\n",
    "            padded_input_ids.append(ids)\n",
    "            padded_attention_mask.append(mask)\n",
    "            padded_labels.append(label)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(padded_input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(padded_attention_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(padded_labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ea0f9-8ab6-4fdd-b30a-365bf9c6ed69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:55:03.875568Z",
     "iopub.status.busy": "2025-07-23T07:55:03.875051Z",
     "iopub.status.idle": "2025-07-23T07:55:03.891172Z",
     "shell.execute_reply": "2025-07-23T07:55:03.889909Z",
     "shell.execute_reply.started": "2025-07-23T07:55:03.875536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = CustomDataCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09c81b-9685-416e-807f-de324d329855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:55:05.665222Z",
     "iopub.status.busy": "2025-07-23T07:55:05.664818Z",
     "iopub.status.idle": "2025-07-23T07:55:05.682338Z",
     "shell.execute_reply": "2025-07-23T07:55:05.681542Z",
     "shell.execute_reply.started": "2025-07-23T07:55:05.665189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import TrainerCallback, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc50812-1530-407c-a064-e2dd466ffb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:55:10.395129Z",
     "iopub.status.busy": "2025-07-23T07:55:10.394567Z",
     "iopub.status.idle": "2025-07-23T07:55:10.415278Z",
     "shell.execute_reply": "2025-07-23T07:55:10.414476Z",
     "shell.execute_reply.started": "2025-07-23T07:55:10.395092Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainingMetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # будем ловить при каждом логировании 'loss'\n",
    "        if logs is None:\n",
    "            return\n",
    "        if \"loss\" in logs:\n",
    "            self.train_loss.append(logs[\"loss\"])\n",
    "\n",
    "    def plot(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(self.train_loss, label=\"train_loss\")\n",
    "        plt.xlabel(\"logging steps\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"train_loss.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea644a7-f057-401e-bdb7-fd951f3a124d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:55:12.532215Z",
     "iopub.status.busy": "2025-07-23T07:55:12.531730Z",
     "iopub.status.idle": "2025-07-23T07:55:12.544960Z",
     "shell.execute_reply": "2025-07-23T07:55:12.544186Z",
     "shell.execute_reply.started": "2025-07-23T07:55:12.532181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_cb = TrainingMetricsCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba596fe5-ce89-4723-a20f-c6254f124139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:55:33.547964Z",
     "iopub.status.busy": "2025-07-23T07:55:33.547514Z",
     "iopub.status.idle": "2025-07-23T07:55:33.565479Z",
     "shell.execute_reply": "2025-07-23T07:55:33.564669Z",
     "shell.execute_reply.started": "2025-07-23T07:55:33.547942Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging_dir = '/home/jupyter/datasphere/project/log_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131c763-261f-4210-ab18-a5fb5ca2908c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:58:07.488753Z",
     "iopub.status.busy": "2025-07-23T07:58:07.488312Z",
     "iopub.status.idle": "2025-07-23T07:58:07.527121Z",
     "shell.execute_reply": "2025-07-23T07:58:07.526176Z",
     "shell.execute_reply.started": "2025-07-23T07:58:07.488732Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=1e-3,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    bf16=True,\n",
    "    label_names=[\"labels\"],\n",
    "    \n",
    "    report_to='none',\n",
    "    \n",
    "    logging_steps=35,\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    logging_dir=logging_dir,\n",
    "    \n",
    "    save_strategy=\"no\",\n",
    "    output_dir=OUTPUT_DIR\n",
    "    \n",
    "    # output_dir=OUTPUT_DIR,\n",
    "    # save_strategy=\"steps\",\n",
    "    # save_steps=200,\n",
    "    # save_total_limit=2    \n",
    "    \n",
    "    #per_device_eval_batch_size=8\n",
    "    # do_eval=False,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=100,\n",
    "    # load_best_model_at_end=True,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe7f51-2008-4be3-b414-fe179ed093ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:58:08.355811Z",
     "iopub.status.busy": "2025-07-23T07:58:08.355429Z",
     "iopub.status.idle": "2025-07-23T07:58:08.381717Z",
     "shell.execute_reply": "2025-07-23T07:58:08.380892Z",
     "shell.execute_reply.started": "2025-07-23T07:58:08.355783Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[metrics_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933df41-f217-4369-99f3-ed6447f9bc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T07:58:11.003124Z",
     "iopub.status.busy": "2025-07-23T07:58:11.002455Z",
     "iopub.status.idle": "2025-07-23T08:23:33.941837Z",
     "shell.execute_reply": "2025-07-23T08:23:33.940897Z",
     "shell.execute_reply.started": "2025-07-23T07:58:11.003099Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee7179-46e9-47ac-8029-95d5adff860d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T08:27:47.449201Z",
     "iopub.status.busy": "2025-07-23T08:27:47.448723Z",
     "iopub.status.idle": "2025-07-23T08:31:13.780209Z",
     "shell.execute_reply": "2025-07-23T08:31:13.779305Z",
     "shell.execute_reply.started": "2025-07-23T08:27:47.449179Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"/home/jupyter/datasphere/project/check_sft\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
